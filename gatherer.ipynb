{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "from bitmex import bitmex\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress, message):\n",
    "    ### Arguements\n",
    "    # progress - int or float of percentage done\n",
    "    # message  - anything you want to relay to the right of the progress-bar\n",
    "    sys.stdout.write('\\r[{0}{1}] {2}'.format('#'*int(progress/4), '_'*(25 - int(progress/4)), f\"{round(progress,2)}% {message}\")),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, filename):\n",
    "    print(\"\")\n",
    "    sys.stdout.write('\\rSaving...'.format(filename)),\n",
    "    df.to_csv(filename)\n",
    "    sys.stdout.write('\\r{0} saved..!\\n'.format(filename)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_bitmex_data_to_csv(symbols_to_get, kline_size):\n",
    "    global new_data\n",
    "    new_data = False\n",
    "    print(\"Downloading data...\")\n",
    "    for symbol in symbols_to_get:\n",
    "        \n",
    "        filename = f\"{symbol}-{kline_size}-data.csv\"\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            mydf = pd.read_csv(filename)\n",
    "            oldest_point_of_data = parser.parse(mydf[\"timestamp\"].iloc[-1]) + timedelta(minutes = + binsizes[kline_size])\n",
    "            latest_point_of_data = client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=True).result()[0][0]['timestamp']\n",
    "        else:\n",
    "            mydf = pd.DataFrame()\n",
    "            oldest_point_of_data = client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=False).result()[0][0]['timestamp']\n",
    "            latest_point_of_data = client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=True).result()[0][0]['timestamp']\n",
    "        \n",
    "        delta_time = latest_point_of_data - oldest_point_of_data\n",
    "        delta_minutes = delta_time.days * 24 * 60 + delta_time.seconds / 60\n",
    "        available_data = math.ceil(delta_minutes/binsizes[kline_size])\n",
    "        rounds = math.ceil(available_data / batch_size)\n",
    "        \n",
    "        if rounds == 0:\n",
    "            print(f\"No new data for {symbol}..!\")\n",
    "            \n",
    "        else:\n",
    "            new_data = True\n",
    "            print(\"\\n\" + str(delta_time) + \" data available for \" + symbol + \" (\" + str(available_data) + \" points of \" + kline_size + \" data)\")\n",
    "            for x in range(rounds):\n",
    "                time.sleep(1) # To prevent API overflow, only allowed to call once pr. second.\n",
    "                new_time = (oldest_point_of_data + timedelta(minutes = x * batch_size * binsizes[kline_size]))\n",
    "                data = client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=batch_size, startTime = new_time).result()[0]\n",
    "                temp_df = pd.DataFrame(data)\n",
    "                mydf = mydf.append(temp_df)\n",
    "                progress = (x + 1) / rounds * 100\n",
    "                update_progress(progress, f\"Downloading round {x + 1} / {rounds}\")\n",
    "\n",
    "            mydf.set_index(\"timestamp\", inplace=True)\n",
    "            mydf = mydf[[\"close\", \"high\", \"low\", \"open\", \"trades\", \"volume\", \"vwap\", \"turnover\"]] # Which columns to save\n",
    "            \n",
    "            save_to_csv(mydf, filename)\n",
    "\n",
    "    print(\"\\nAll caught up..!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_clean(symbols_to_get, kline_size, save = False):\n",
    "    if new_data:\n",
    "        print(\"Merging data...\")\n",
    "        for symbol in symbols_to_get:\n",
    "\n",
    "            progress = (symbols_to_get.index(symbol) + 1) / len(symbols_to_get) * 100\n",
    "            update_progress(progress, f\"Adding {symbol} to dataframe\")\n",
    "            filename = f\"{symbol}-{kline_size}-data.csv\"\n",
    "            temp_df = pd.read_csv(filename)\n",
    "\n",
    "            # rename volume and close to include the ticker so we can still which close/volume is which:\n",
    "            temp_df.rename(columns={\"close\": f\"{symbol}_close\",\n",
    "                               \"high\": f\"{symbol}_high\",\n",
    "                               \"low\": f\"{symbol}_low\",\n",
    "                               \"open\": f\"{symbol}_open\",\n",
    "                               \"trades\": f\"{symbol}_trades\",\n",
    "                               \"volume\": f\"{symbol}_volume\",\n",
    "                               \"vwap\": f\"{symbol}_vwap\",\n",
    "                               \"turnover\": f\"{symbol}_turnover\"}, inplace=True)\n",
    "\n",
    "            temp_df.set_index(\"timestamp\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "            temp_df = temp_df[[f\"{symbol}_close\",\n",
    "                               f\"{symbol}_high\",\n",
    "                               f\"{symbol}_low\",\n",
    "                               f\"{symbol}_open\",\n",
    "                               f\"{symbol}_trades\",\n",
    "                               f\"{symbol}_volume\",\n",
    "                               f\"{symbol}_vwap\",\n",
    "                               f\"{symbol}_turnover\"]]  # ignore the other columns besides price and volume\n",
    "\n",
    "            if symbols_to_get.index(symbol)==0:\n",
    "                mydf = temp_df\n",
    "            else:\n",
    "                mydf = mydf.join(temp_df)\n",
    "\n",
    "        update_progress(100.0, f\"Dataframe is complete..!\")\n",
    "\n",
    "        mydf = mydf.astype(\"float64\") # Makes sure that all values are treated as the same type\n",
    "        mydf[mydf==np.inf]=np.nan # Converts any inf values to nan\n",
    "        mydf.fillna(method=\"ffill\", inplace=True)  # Any gaps in the data is filled with previously known values (ffill = forward fill)\n",
    "        mydf.dropna(inplace=True) # Despite the fact that there shouldn't be any nans left we still use dropna to make sure\n",
    "\n",
    "        if save:\n",
    "            filename = f\"Merged-{kline_size}-data.csv\"\n",
    "            save_to_csv(mydf, filename)\n",
    "    else:\n",
    "        print(\"No new data, no merging required...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### API\n",
    "api_key = '[REDACTED]'\n",
    "api_secret = '[REDACTED]'\n",
    "\n",
    "### SETTINGS\n",
    "symbols_to_get = [\"XBTUSD\", \"ETHUSD\", \"XRPZ18\", \"LTCZ18\", \"EOSZ18\", \"BCHZ18\", \"ADAZ18\", \"TRXZ18\"]\n",
    "kline_size = \"1m\"\n",
    "\n",
    "### CONSTANTS / GLOBALS\n",
    "\n",
    "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
    "batch_size = 750\n",
    "client = bitmex(test=False, api_key=api_key, api_secret=api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "\n",
      "0:02:00 data available for XBTUSD (2 points of 1m data)\n",
      "[#########################] 100.0% Downloading round 1 / 1\n",
      "XBTUSD-1m-data.csv saved..!\n",
      "\n",
      "0:03:00 data available for ETHUSD (3 points of 1m data)\n",
      "[#########################] 100.0% Downloading round 1 / 1\n",
      "ETHUSD-1m-data.csv saved..!\n",
      "\n",
      "0:02:00 data available for XRPZ18 (2 points of 1m data)\n",
      "[#########################] 100.0% Downloading round 1 / 1\n",
      "XRPZ18-1m-data.csv saved..!\n",
      "\n",
      "0:02:00 data available for LTCZ18 (2 points of 1m data)\n",
      "[#########################] 100.0% Downloading round 1 / 1\n",
      "LTCZ18-1m-data.csv saved..!\n",
      "\n",
      "0:02:00 data available for EOSZ18 (2 points of 1m data)\n",
      "[#########################] 100.0% Downloading round 1 / 1\n",
      "EOSZ18-1m-data.csv saved..!\n",
      "\n",
      "0:02:00 data available for BCHZ18 (2 points of 1m data)\n",
      "[#########################] 100.0% Downloading round 1 / 1\n",
      "BCHZ18-1m-data.csv saved..!\n",
      "\n",
      "0:01:00 data available for ADAZ18 (1 points of 1m data)\n",
      "[#########################] 100.0% Downloading round 1 / 1\n",
      "ADAZ18-1m-data.csv saved..!\n",
      "\n",
      "0:01:00 data available for TRXZ18 (1 points of 1m data)\n",
      "[#########################] 100.0% Downloading round 1 / 1\n",
      "TRXZ18-1m-data.csv saved..!\n",
      "\n",
      "All caught up..!\n",
      "\n",
      "Merging data...\n",
      "[#########################] 100.0% Dataframe is complete..!\n",
      "Merged-1m-data.csv saved..!\n"
     ]
    }
   ],
   "source": [
    "### It's runtime baby\n",
    "clear_output()\n",
    "download_bitmex_data_to_csv(symbols_to_get, kline_size)\n",
    "merge_and_clean(symbols_to_get, kline_size, save = True)\n",
    "if not new_data:\n",
    "    time.sleep(5) # This should prevent API overflow in case of constant looping when checking encountering no new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
